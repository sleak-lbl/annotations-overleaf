\subsection{Tools}
\begin{itemize}
\item get.py for querying an annotation database
\item what do we have for building an annotation database? (Ann's tool for ingesting the mutrino and jobs info?)
\item framework for working with rdf graph

(plan is to have cataloging and running general queries supported at least, and ideally also slicing-and-fetching of timestamped logs in line-per-timestamp format)
\end{itemize}

from intro:
      While nothing prevents annotators and researchers from directly
      annotating, describing and querying collections with SQL and RDF,
      the learning curve for these technologies presents an entry
      barrier to the time-constrained individuals who would otherwise
      benefit from it.

      Many interactions with annotated, discoverable log data can be
      can be described in just a few use cases:

\begin{itemize}
\item Cataloging a collection to make it discoverable
\item Annotating specific logs, either to add expert commentary to
      entries of interest or to associate human observations with log
      entries, log subjects or time periods
\item Finding data relevant to a subject and time period of interest
\item Extracting slices of logs associated with specific annotations,
      or periods and subjects of interest
\end{itemize}

     The diversity of data sources and formats mean that these use cases
     can be extended almost indefinitely, and providing a generalized
     interface to every conceivable HPC component and data format is
     not the goal here (see philosophy point \textcolor{red}{X}). We
     do, however, provide an extensible tooling infrastructure and tools
     for some basic and common scenarios.



- talk about why, eg rdf because it is machine readable, supports adding tools etc over time 

\subsubsection{Creating Annotations}

To faciliate the creation of log line annotaitons
and the identification of the occurences of events to be annotated,
we have been using two tools.

LogDiver~\cite{LogDiver} is a tool developed by UIUC which includes a set of regular expressions defining
events in log files of interest; the regular expressions are associated with categorizations
which are a subset of those described in the previous section; the
category name, \texttt{LDxxx}, was chosen to refelct our intention to map to the
Log Diver categroizations where possible.
LogDiver itself is used to discover the occurences of the regular
expresssions in the logs and to determine statistics and infroamtin about event sequences
such as statistics of failure events, or of timigns of failures and recoveries.
LogDiver, or any such regex-based tool (e.g., SEC~\cite{SEC}) can be used to efficiently extract events
and annotate them, based on the intention of the extistence of the regex.

For the dataset descirbed in this work, we prinicpally used Baler~\cite{Baler} for
identifying the log lines to be annotated and for extracing them from the dataset.
Baler extracts patterns from log files without requiring aprior knowledge of
regex. Rather, Baler takes dictionaries of ''words''; words appearing in the log lines
are the passed through to the pattern and non-words become a wildcard in the pattern.
Wildcards of certain formats, for example numbers, hex dumps, char arrays, hostnames and link names
(in cname format for Cray systems) are represented as that formatted type in the pattern.
For example, every instance of the log message \texttt{mutrino-smw 24626 found\_critical\_aries\_error: Processing ''PCI-e CMPL\_TIMEOUT'' critical error (0x660e)}
is represented by the pattern \texttt{<host> nlrd <pid> found\_critical\_aries\_error: Processing ''* *\_TIMEOUT'' critical error (<num>)}.
This illustrates where words, formatted wildcards, and unformatted wildcards (represented by \texttt{*}) appear in the pattern.

For Cray systems, we augment
the dictionary with an architecture specific dictionary of about 100 words (e.g., Lustre, DIMM).
For 3 months of data from our Trinity test system, Mutrino, a 100 node XC 40,
we had over 120 million text log lines which were reduced to 15500 patterns. To further identify patterns
of interest, we weight the patterns by the occurence of 50 weighted
keywords (e.g., congestion = 1.5, error = 1.5, degrade = 0.75). This further reduced the patterns
to 2500 significantly weighted patterns. For example the pattern
\texttt{<host> nlrd <pid> ***ERROR***: Link recovery operation failed; error <num>} has
an aggregate weight of 5.5. From those, we chose 150
patterns to annotate with enhanced descirptions. This resulted in about 860,000
annotated log line instances.

It is our intention to
build a plugin to interface with Baler, and support the annotations there,
however in the prototype, we merely annotated the extracted patterns from
Baler and loaded them into the database.
We do, however, include the Baler pattern id in the annotation fields
for reference ease; only the annotation description, not the original log line nor the pattern
are stored in the annotation database.

Some example patterns, from which the originating log line will be obvious, and
the resulting annotation used in this work, are given in Figure~\ref{f:baler}

\begin{figure*}
\begin{annol}

Baler pattern, preceeded by weight (W=#) and balerpatternid number:
(W=5)        258   HWERR[<host>][<num>]:<num>:SSID RSP A_STATUS_ORB_TIMEOUT Error:*=<num>:*=<num>:*=<num>
Annotation:
authorid:acg  description: 'ORB timeout waiting on outstanding request(s) in the buffer'  LDcatgroup: NE

Baler pattern and weight:
(W=3.75)     498   <host> nlrd <pid> do_set_alerts: <num> links failed, <num> blades failed, <num> blade critical faults, *_in_progress <num>, *_*_reroute <num>; reroute required
Annotation:
authorid:acg  description: 'Setting alerts due to failures. A network reroute is required' LDcatgroup: NE

Baler pattern and weight:
(W=3.25)     748   <host> nlrd <pid> ***ERROR***: Warm swap operation failed; error <num>
Annotation:
authorid:acg description: 'Warm swap failed. This is in response to a operation intended to reset/reinit/replace a component (including network components).' LDcatgroup: NO

Baler pattern and weight:
(W=1.5)      705   <host> nlrd <pid> responder_work_*: Top <num> nodes involved with network congestion
Annotation:
authorid:acg description 'System computing and listing congestion candidate applications' LDcatgroup:NE
\end{annol}
\caption{Example Baler patterns extracted from log lines and their annotated versions. Events to annotate are based on
knowledge of significant events. Annotation descriptions can provide additional context to non-self-explanatory log messages.}
\label{f:baler}
\end{figure*}


We fed Baler with the Cray logs as they resided on the SMW This requires us
to do some file-specific format extraction of messages, timestamps,
and components (e.g., \texttt{netwatch}, \texttt{hwerrlog}) which we may not have had to do if
we fed it raw syslog versions of the files or datastream however, this also enables us
to include the log file type (e.g., \texttt{nlrd}, \texttt{hwerrlog}) in the pattern metadata,
whcih aids the log file look up. For many cases, messages are reported
on the SMW with the component association of the SMW. For some cases, we can
extract the actual component of interest, for example, from the Baler pattern
\texttt{<host> nlrd <pid> found\_critical\_aries\_error: handling failed * link on <host> (node )}
we can infer the fields from which to extract the \texttt{host} and \texttt{node} to which
the annotation should be associated. Other messages refer to actions by the SMW for which
the component cannot be inferred. In these cases the component assignment will either be
the smw or 'unknown'.

We used Baler for all major log processing, except for the \texttt{command} log, which required us
to associate \texttt{START} and \texttt{END} of events, for which we used a perl script. This
log includes both manually initiated and automatically invoked commands of
interest such as warmswaps, boots, etc. This was particularly useful for
determining manual actions that may not have been well documented by the
system administrators. This resulted in another 2000 annotations. In addition,
we extracted the times of reboots from the datatime in the name of the \texttt{p0-XXX}
directories. All annotations from these two sources are attributed as manually induced.

Some other system administrator actions were recorded by manually generated annotations
(about 10, in this case). Ticketing systems may be used to generate such annotations as well.
Knowledge of such events is useful for understanding the root causes and resolution of errors
in the dataset. These annotations were generated manually.

Other non-log events include external actions by non-administrators
such as facilities tests, fault injection research, which require
annotations by differnet people. These were also generated manually
for this dataset. Similar to the Baler Annotations, for the
prototype these were loaded into the same annotation database.

Log data was extracted from alps logs, which was the scheduler in use for
this time period. This could be replaced with queries to a slurm,
or similar, database or interface, where available.

Recall that the main aim of the annotations
is to provide a reduced set of searchable, understandable data, with the
ability to use the annotations to further more detailed search of the raw
logs, if possible and desired. This differs from tools
such as SEC, which is intended to enable action upon the run time
occurence of a log line matching a regex (e.g., notification
of failed component), or Splunk, which is intended
to facilitate knowledge of the occurences of pre-defined
events with accompaning statistical plots.








